{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOCi0of+Dfu3IRsselHNVAj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "79728b32ffbe42e888d0eea1476bd453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_681a767d2536450bb6efe7bae19dcb91",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1626cf9e737a4a169c6907fe9879c8a5",
              "IPY_MODEL_e115aed75b0c4178bc9252de514a0ce1"
            ]
          }
        },
        "681a767d2536450bb6efe7bae19dcb91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1626cf9e737a4a169c6907fe9879c8a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8fb04d07f37d47009e87fe1ec576fc3c",
            "_dom_classes": [],
            "description": "Epoch",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1988d91626a6401cb874d4e7171e093a"
          }
        },
        "e115aed75b0c4178bc9252de514a0ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_745c155d3eec4822ba181ac2f2be86da",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 2/2 [2:18:34&lt;00:00, 4157.56s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7365191df6f47d8bf10a6307525ba5a"
          }
        },
        "8fb04d07f37d47009e87fe1ec576fc3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1988d91626a6401cb874d4e7171e093a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "745c155d3eec4822ba181ac2f2be86da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7365191df6f47d8bf10a6307525ba5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25de5ba4902b4618b287cb1a39094abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_328f1eefab8b47a8a59b705c895af0a1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8a6e41cea65441e6a6832c7d308be6f8",
              "IPY_MODEL_28687e9f73a248ddb68468f3f4bd2b22"
            ]
          }
        },
        "328f1eefab8b47a8a59b705c895af0a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a6e41cea65441e6a6832c7d308be6f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4a98640e900d487491cf66482718c6f6",
            "_dom_classes": [],
            "description": "Iteration",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 8428,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8428,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_931f7bb62ce44822a14af33a597e7a6f"
          }
        },
        "28687e9f73a248ddb68468f3f4bd2b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_105a0f8496f34de397cf69e246cbde85",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 8428/8428 [1:09:17&lt;00:00,  2.06it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d504d3deca2d4040a36e2597a6a36811"
          }
        },
        "4a98640e900d487491cf66482718c6f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "931f7bb62ce44822a14af33a597e7a6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "105a0f8496f34de397cf69e246cbde85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d504d3deca2d4040a36e2597a6a36811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb815869c4174241b7703f5b9e757a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8e66b73dd4ce4201a84eeeb1f8f16746",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_76736fff859341a8b2c252dcf42905a2",
              "IPY_MODEL_48fd182d10984b3bb79e246841f28483"
            ]
          }
        },
        "8e66b73dd4ce4201a84eeeb1f8f16746": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76736fff859341a8b2c252dcf42905a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e62d5341760845aaacb3ff4e950f08dd",
            "_dom_classes": [],
            "description": "Iteration",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 8428,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8428,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0626490259544fabbe266570d83313b"
          }
        },
        "48fd182d10984b3bb79e246841f28483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_718998b1868e44448e7226984fd70b14",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 8428/8428 [1:09:16&lt;00:00,  2.06it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c18b43aa339e493daeff053d70bccace"
          }
        },
        "e62d5341760845aaacb3ff4e950f08dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0626490259544fabbe266570d83313b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "718998b1868e44448e7226984fd70b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c18b43aa339e493daeff053d70bccace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snest21/TP-Model/blob/master/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PmF8k-_8qrF",
        "colab_type": "code",
        "outputId": "ed238dae-6e5a-4115-985c-d1dedb34e7ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "%%js\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"colab-connect-button\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "function ClickConnect(){\n",
              "console.log(\"Working\"); \n",
              "document.querySelector(\"colab-toolbar-button\").click() \n",
              "}setInterval(ClickConnect,60000)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hM6TWvhktFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "while True:\n",
        "    a.append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Utm8nIZVlzVq",
        "colab_type": "code",
        "outputId": "f083b194-99d1-4fa5-cb9a-e2ba3b9d9e9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/ccasimiro88/TranslateAlignRetrieve.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TranslateAlignRetrieve'...\n",
            "remote: Enumerating objects: 351, done.\u001b[K\n",
            "remote: Counting objects: 100% (351/351), done.\u001b[K\n",
            "remote: Compressing objects: 100% (228/228), done.\u001b[K\n",
            "remote: Total 351 (delta 210), reused 236 (delta 112), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (351/351), 14.50 MiB | 7.13 MiB/s, done.\n",
            "Resolving deltas: 100% (210/210), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J4miNmacb0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eXdABpEl1S4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install cdqa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRJGb28al370",
        "colab_type": "code",
        "outputId": "a079ea13-0edc-4289-92cf-e051832aae09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import joblib\n",
        "from cdqa.reader import BertProcessor, BertQA"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tqdm/autonotebook/__init__.py:18: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcEVw7a7l6xk",
        "colab_type": "code",
        "outputId": "866df65a-8350-4087-ad4d-a4d3826e4554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%time\n",
        "train_processor = BertProcessor(do_lower_case=True, is_training=True)\n",
        "train_examples, train_features = train_processor.fit_transform(X='./TranslateAlignRetrieve/SQuAD-es-v1.1/train-v1.1-es.json')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 321101.23B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 15min 3s, sys: 4.08 s, total: 15min 7s\n",
            "Wall time: 15min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXZ9sEUImjlA",
        "colab_type": "code",
        "outputId": "bcfd1b62-06c9-4dd4-cb77-dfd099f12049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198,
          "referenced_widgets": [
            "79728b32ffbe42e888d0eea1476bd453",
            "681a767d2536450bb6efe7bae19dcb91",
            "1626cf9e737a4a169c6907fe9879c8a5",
            "e115aed75b0c4178bc9252de514a0ce1",
            "8fb04d07f37d47009e87fe1ec576fc3c",
            "1988d91626a6401cb874d4e7171e093a",
            "745c155d3eec4822ba181ac2f2be86da",
            "f7365191df6f47d8bf10a6307525ba5a",
            "25de5ba4902b4618b287cb1a39094abd",
            "328f1eefab8b47a8a59b705c895af0a1",
            "8a6e41cea65441e6a6832c7d308be6f8",
            "28687e9f73a248ddb68468f3f4bd2b22",
            "4a98640e900d487491cf66482718c6f6",
            "931f7bb62ce44822a14af33a597e7a6f",
            "105a0f8496f34de397cf69e246cbde85",
            "d504d3deca2d4040a36e2597a6a36811",
            "eb815869c4174241b7703f5b9e757a15",
            "8e66b73dd4ce4201a84eeeb1f8f16746",
            "76736fff859341a8b2c252dcf42905a2",
            "48fd182d10984b3bb79e246841f28483",
            "e62d5341760845aaacb3ff4e950f08dd",
            "b0626490259544fabbe266570d83313b",
            "718998b1868e44448e7226984fd70b14",
            "c18b43aa339e493daeff053d70bccace"
          ]
        }
      },
      "source": [
        "%%time\n",
        "reader = BertQA(bert_model='bert-base-multilingual-cased',\n",
        "                train_batch_size=12,\n",
        "                learning_rate=3e-5,\n",
        "                num_train_epochs=2,\n",
        "                do_lower_case=True,\n",
        "                output_dir='models')\n",
        "\n",
        "reader.fit(X=(train_examples, train_features))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 569/569 [00:00<00:00, 279358.42B/s]\n",
            "100%|██████████| 714314041/714314041 [00:48<00:00, 14780769.93B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79728b32ffbe42e888d0eea1476bd453",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=2, style=ProgressStyle(description_width='initial…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25de5ba4902b4618b287cb1a39094abd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Iteration', max=8428, style=ProgressStyle(description_width='…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb815869c4174241b7703f5b9e757a15",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Iteration', max=8428, style=ProgressStyle(description_width='…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 1h 25min 28s, sys: 53min 30s, total: 2h 18min 58s\n",
            "Wall time: 2h 19min 36s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNg4bGEqUzal",
        "colab_type": "code",
        "outputId": "684b4e31-1c84-44cd-fbc8-1cd6fb970027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "reader.model.to('cpu')\n",
        "reader.device = torch.device('cpu')\n",
        "joblib.dump(reader, os.path.join(reader.output_dir, 'bert_qa2.joblib'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['models/bert_qa2.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8t227jBUf0l",
        "colab_type": "code",
        "outputId": "dec65d1e-2594-4e75-fbf3-1e9321efcf9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCguO9hkU3ma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -a ./models ./drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3TsARA8U9S7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cdqa.pipeline import QAPipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRs4ziKkVOiu",
        "colab_type": "code",
        "outputId": "1330a8bd-8cc7-4b21-91ea-17d220c39a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%time\n",
        "from cdqa.utils.evaluation import evaluate_reader\n",
        "from cdqa.utils.download import *\n",
        "\n",
        "cdqa_pipeline = QAPipeline(reader='./models/bert_qa2.joblib')\n",
        "eval_dict = evaluate_reader(cdqa_pipeline, \"./TranslateAlignRetrieve/SQuAD-es-v1.1/dev-v1.1-es.json\")\n",
        "\n",
        "print(eval_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'exact_match': 42.686849574266795, 'f1': 60.87823252102742}\n",
            "CPU times: user 4min 10s, sys: 1min 4s, total: 5min 14s\n",
            "Wall time: 5min 16s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSyK3ADiXoYP",
        "colab_type": "code",
        "outputId": "abb7a3f4-3149-4517-be63-fd6e08277e7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%time\n",
        "from cdqa.utils.evaluation import evaluate_reader\n",
        "from cdqa.utils.download import *\n",
        "\n",
        "cdqa_pipeline = QAPipeline(reader='./models/bert_qa2.joblib')\n",
        "eval_dict = evaluate_reader(cdqa_pipeline, \"./xquad/xquad.es.json\")\n",
        "\n",
        "print(eval_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'exact_match': 38.319327731092436, 'f1': 60.21350291427889}\n",
            "CPU times: user 31.6 s, sys: 8.5 s, total: 40.1 s\n",
            "Wall time: 41.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YwlYITWYd9Z",
        "colab_type": "code",
        "outputId": "1788a0cf-1dce-469f-b4d0-5c2f1bc78fa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "%%time\n",
        "from cdqa.utils.evaluation import evaluate_reader\n",
        "from cdqa.utils.download import *\n",
        "\n",
        "cdqa_pipeline = QAPipeline(reader='./models/bert_qa2.joblib')\n",
        "eval_dict = evaluate_reader(cdqa_pipeline, \"./MLQA_V1/dev/dev-context-es-question-es.json\")\n",
        "\n",
        "print(eval_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-86b40d558133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from cdqa.utils.evaluation import evaluate_reader\\nfrom cdqa.utils.download import *\\n\\ncdqa_pipeline = QAPipeline(reader=\\'./models/bert_qa2.joblib\\')\\neval_dict = evaluate_reader(cdqa_pipeline, \"./MLQA_V1/dev/dev-context-es-question-es.json\")\\n\\nprint(eval_dict)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/cdqa/utils/evaluation.py\u001b[0m in \u001b[0;36mevaluate_reader\u001b[0;34m(cdqa_pipeline, dataset_file, expected_version)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mexpected_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0;34m\", but got dataset with v-\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0;34m+\u001b[0m \u001b[0mdataset_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"version\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             )\n",
            "\u001b[0;31mTypeError\u001b[0m: must be str, not float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwdq9o4LZW9c",
        "colab_type": "code",
        "outputId": "ade73799-43dd-4976-b281-9b170a55f9b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!head -c 200 ./xquad/xquad.es.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"data\": [\n",
            "    {\n",
            "      \"paragraphs\": [\n",
            "        {\n",
            "          \"context\": \"\\ufeffLos Panthers, que adem\\u00e1s de liderar las intercepciones de la NFL con 24 y contar con cuatro jugadores de la Pro Bow"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_rjDVr7WK4i",
        "colab_type": "code",
        "outputId": "8656fd67-8c37-4c49-9927-cb0db381ca79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/deepmind/xquad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'xquad'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 34 (delta 10), reused 8 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (34/34), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvdTDKiUYBgY",
        "colab_type": "code",
        "outputId": "85a203e5-c588-41c6-c6ba-186b168520ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/MLQA/MLQA_V1.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-08 06:00:30--  https://dl.fbaipublicfiles.com/MLQA/MLQA_V1.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 2606:4700:10::6816:4b8e, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75719050 (72M) [application/zip]\n",
            "Saving to: ‘MLQA_V1.zip’\n",
            "\n",
            "MLQA_V1.zip         100%[===================>]  72.21M  10.5MB/s    in 7.8s    \n",
            "\n",
            "2020-04-08 06:00:39 (9.21 MB/s) - ‘MLQA_V1.zip’ saved [75719050/75719050]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyCm6noOYIwe",
        "colab_type": "code",
        "outputId": "272013f9-b8f5-437e-80fc-b16104481d26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!unzip ./MLQA_V1.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./MLQA_V1.zip\n",
            "   creating: MLQA_V1/\n",
            "   creating: MLQA_V1/dev/\n",
            "  inflating: MLQA_V1/dev/dev-context-ar-question-ar.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-ar-question-de.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-ar-question-en.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-ar-question-es.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-ar-question-hi.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-ar-question-vi.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-ar-question-zh.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-de-question-ar.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-de-question-de.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-de-question-en.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-de-question-es.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-de-question-hi.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-de-question-vi.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-de-question-zh.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-en-question-ar.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-en-question-de.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-en-question-en.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-en-question-es.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-en-question-hi.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-en-question-vi.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-en-question-zh.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-es-question-ar.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-es-question-de.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-es-question-en.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-es-question-es.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-es-question-hi.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-es-question-vi.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-es-question-zh.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-hi-question-ar.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-hi-question-de.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-hi-question-en.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-hi-question-es.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-hi-question-hi.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-hi-question-vi.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-hi-question-zh.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-vi-question-ar.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-vi-question-de.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-vi-question-en.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-vi-question-es.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-vi-question-hi.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-vi-question-vi.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-vi-question-zh.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-zh-question-ar.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-zh-question-de.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-zh-question-en.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-zh-question-es.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-zh-question-hi.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-zh-question-vi.json  \n",
            "  inflating: MLQA_V1/dev/dev-context-zh-question-zh.json  \n",
            "   creating: MLQA_V1/test/\n",
            "  inflating: MLQA_V1/test/test-context-ar-question-ar.json  \n",
            "  inflating: MLQA_V1/test/test-context-ar-question-de.json  \n",
            "  inflating: MLQA_V1/test/test-context-ar-question-en.json  \n",
            "  inflating: MLQA_V1/test/test-context-ar-question-es.json  \n",
            "  inflating: MLQA_V1/test/test-context-ar-question-hi.json  \n",
            "  inflating: MLQA_V1/test/test-context-ar-question-vi.json  \n",
            "  inflating: MLQA_V1/test/test-context-ar-question-zh.json  \n",
            "  inflating: MLQA_V1/test/test-context-de-question-ar.json  \n",
            "  inflating: MLQA_V1/test/test-context-de-question-de.json  \n",
            "  inflating: MLQA_V1/test/test-context-de-question-en.json  \n",
            "  inflating: MLQA_V1/test/test-context-de-question-es.json  \n",
            "  inflating: MLQA_V1/test/test-context-de-question-hi.json  \n",
            "  inflating: MLQA_V1/test/test-context-de-question-vi.json  \n",
            "  inflating: MLQA_V1/test/test-context-de-question-zh.json  \n",
            "  inflating: MLQA_V1/test/test-context-en-question-ar.json  \n",
            "  inflating: MLQA_V1/test/test-context-en-question-de.json  \n",
            "  inflating: MLQA_V1/test/test-context-en-question-en.json  \n",
            "  inflating: MLQA_V1/test/test-context-en-question-es.json  \n",
            "  inflating: MLQA_V1/test/test-context-en-question-hi.json  \n",
            "  inflating: MLQA_V1/test/test-context-en-question-vi.json  \n",
            "  inflating: MLQA_V1/test/test-context-en-question-zh.json  \n",
            "  inflating: MLQA_V1/test/test-context-es-question-ar.json  \n",
            "  inflating: MLQA_V1/test/test-context-es-question-de.json  \n",
            "  inflating: MLQA_V1/test/test-context-es-question-en.json  \n",
            "  inflating: MLQA_V1/test/test-context-es-question-es.json  \n",
            "  inflating: MLQA_V1/test/test-context-es-question-hi.json  \n",
            "  inflating: MLQA_V1/test/test-context-es-question-vi.json  \n",
            "  inflating: MLQA_V1/test/test-context-es-question-zh.json  \n",
            "  inflating: MLQA_V1/test/test-context-hi-question-ar.json  \n",
            "  inflating: MLQA_V1/test/test-context-hi-question-de.json  \n",
            "  inflating: MLQA_V1/test/test-context-hi-question-en.json  \n",
            "  inflating: MLQA_V1/test/test-context-hi-question-es.json  \n",
            "  inflating: MLQA_V1/test/test-context-hi-question-hi.json  \n",
            "  inflating: MLQA_V1/test/test-context-hi-question-vi.json  \n",
            "  inflating: MLQA_V1/test/test-context-hi-question-zh.json  \n",
            "  inflating: MLQA_V1/test/test-context-vi-question-ar.json  \n",
            "  inflating: MLQA_V1/test/test-context-vi-question-de.json  \n",
            "  inflating: MLQA_V1/test/test-context-vi-question-en.json  \n",
            "  inflating: MLQA_V1/test/test-context-vi-question-es.json  \n",
            "  inflating: MLQA_V1/test/test-context-vi-question-hi.json  \n",
            "  inflating: MLQA_V1/test/test-context-vi-question-vi.json  \n",
            "  inflating: MLQA_V1/test/test-context-vi-question-zh.json  \n",
            "  inflating: MLQA_V1/test/test-context-zh-question-ar.json  \n",
            "  inflating: MLQA_V1/test/test-context-zh-question-de.json  \n",
            "  inflating: MLQA_V1/test/test-context-zh-question-en.json  \n",
            "  inflating: MLQA_V1/test/test-context-zh-question-es.json  \n",
            "  inflating: MLQA_V1/test/test-context-zh-question-hi.json  \n",
            "  inflating: MLQA_V1/test/test-context-zh-question-vi.json  \n",
            "  inflating: MLQA_V1/test/test-context-zh-question-zh.json  \n",
            "  inflating: MLQA_V1/LICENSE         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3osNvZi9dmUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVJxwqQQdmdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CblSrh0-dmmA",
        "colab_type": "code",
        "outputId": "c84fc536-3e77-4198-8447-d9f2c630e742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.35)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 8.1MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.35 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.35)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.35->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.35->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=135986b5084baba118602ab02d63b643bdac0345c3fa2ffb1f034115f7c145dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPm7YjE1dmsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python transformers/examples/run_squad.py \\\n",
        "  --model_type bert \\\n",
        "  --model_name_or_path ./model_output \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --do_lower_case \\\n",
        "  --train_file ./TranslateAlignRetrieve/SQuAD-es-v2.0/train-v2.0-es.json \\\n",
        "  --predict_file ./TranslateAlignRetrieve/SQuAD-es-v2.0/dev-v2.0-es.json \\\n",
        "  --per_gpu_train_batch_size 12 \\\n",
        "  --learning_rate 3e-5 \\\n",
        "  --num_train_epochs 2.0 \\\n",
        "  --max_seq_length 384 \\\n",
        "  --doc_stride 128 \\\n",
        "  --output_dir ./model_output \\\n",
        "  --save_steps 5000 \\\n",
        "  --threads 4 \\\n",
        "  --version_2_with_negative "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhGQ7kzWeYFN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "!cp -a ./model_output ./drive/My\\ Drive/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0oLxHf8i6do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!bash ./TranslateAlignRetrieve/src/qa/download_mlqa_xquad.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkceIsxhiYJ7",
        "colab_type": "code",
        "outputId": "df098c39-9a4a-4691-c9a5-e58f16389feb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python ./transformers/examples/run_squad.py \\\n",
        "         --model_type bert \\\n",
        "         --model_name_or_path ./model_output \\\n",
        "         --train_file ./TranslateAlignRetrieve/SQuAD-es-v2.0/train-v2.0-es.json \\\n",
        "         --do_eval \\\n",
        "         --predict_file ./TranslateAlignRetrieve/src/qa/corpora/MLQA_V1/test/test-context-es-question-es.json \\\n",
        "         --overwrite_cache \\\n",
        "         --n_best_size 5 \\\n",
        "         --output_dir ./model_results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-08 20:55:46.333089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "04/08/2020 20:55:48 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "04/08/2020 20:55:48 - INFO - transformers.configuration_utils -   loading configuration file ./model_output/config.json\n",
            "04/08/2020 20:55:48 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "04/08/2020 20:55:48 - INFO - transformers.configuration_utils -   loading configuration file ./model_output/config.json\n",
            "04/08/2020 20:55:48 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "04/08/2020 20:55:48 - INFO - transformers.tokenization_utils -   Model name './model_output' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming './model_output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "04/08/2020 20:55:48 - INFO - transformers.tokenization_utils -   Didn't find file ./model_output/added_tokens.json. We won't load it.\n",
            "04/08/2020 20:55:48 - INFO - transformers.tokenization_utils -   loading file ./model_output/vocab.txt\n",
            "04/08/2020 20:55:48 - INFO - transformers.tokenization_utils -   loading file None\n",
            "04/08/2020 20:55:48 - INFO - transformers.tokenization_utils -   loading file ./model_output/special_tokens_map.json\n",
            "04/08/2020 20:55:48 - INFO - transformers.tokenization_utils -   loading file ./model_output/tokenizer_config.json\n",
            "04/08/2020 20:55:48 - INFO - transformers.modeling_utils -   loading weights file ./model_output/pytorch_model.bin\n",
            "04/08/2020 20:55:54 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, lang_id=0, learning_rate=5e-05, local_rank=-1, logging_steps=500, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='./model_output', model_type='bert', n_best_size=5, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='./model_results', overwrite_cache=True, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='./TranslateAlignRetrieve/src/qa/corpora/MLQA_V1/test/test-context-es-question-es.json', save_steps=500, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file='./TranslateAlignRetrieve/SQuAD-es-v2.0/train-v2.0-es.json', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)\n",
            "04/08/2020 20:55:54 - INFO - __main__ -   Loading checkpoint ./model_output for evaluation\n",
            "04/08/2020 20:55:54 - INFO - __main__ -   Evaluate the following checkpoints: ['./model_output']\n",
            "04/08/2020 20:55:54 - INFO - transformers.configuration_utils -   loading configuration file ./model_output/config.json\n",
            "04/08/2020 20:55:54 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "04/08/2020 20:55:54 - INFO - transformers.modeling_utils -   loading weights file ./model_output/pytorch_model.bin\n",
            "04/08/2020 20:55:57 - INFO - __main__ -   Creating features from dataset file at .\n",
            "100% 2503/2503 [00:01<00:00, 1858.79it/s]\n",
            "convert squad examples to features: 100% 5253/5253 [00:23<00:00, 227.48it/s]\n",
            "add example index and unique id: 100% 5253/5253 [00:00<00:00, 839276.20it/s]\n",
            "04/08/2020 20:56:21 - INFO - __main__ -   Saving features into cached file ./cached_dev_model_output_384\n",
            "04/08/2020 20:56:28 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "04/08/2020 20:56:28 - INFO - __main__ -     Num examples = 5441\n",
            "04/08/2020 20:56:28 - INFO - __main__ -     Batch size = 8\n",
            "Evaluating: 100% 681/681 [01:12<00:00,  9.35it/s]\n",
            "04/08/2020 20:57:41 - INFO - __main__ -     Evaluation done in total 72.818245 secs (0.013383 sec per example)\n",
            "04/08/2020 20:57:41 - INFO - transformers.data.metrics.squad_metrics -   Writing predictions to: ./model_results/predictions_.json\n",
            "04/08/2020 20:57:41 - INFO - transformers.data.metrics.squad_metrics -   Writing nbest to: ./model_results/nbest_predictions_.json\n",
            "04/08/2020 20:57:47 - INFO - __main__ -   Results: {'exact': 42.94688749286122, 'f1': 66.90312764718452, 'total': 5253, 'HasAns_exact': 42.94688749286122, 'HasAns_f1': 66.90312764718452, 'HasAns_total': 5253, 'best_exact': 42.94688749286122, 'best_exact_thresh': 0.0, 'best_f1': 66.90312764718452, 'best_f1_thresh': 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5CazHMdkyuX",
        "colab_type": "code",
        "outputId": "ee39210e-f074-4547-d0e9-9ba43c71ecdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/deepmind/xquad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'xquad'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 34 (delta 10), reused 8 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (34/34), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8YVJ6fMmQdj",
        "colab_type": "code",
        "outputId": "cfe0c182-6e78-4d56-f7cd-1106b4937630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python ./transformers/examples/run_squad.py \\\n",
        "         --model_type bert \\\n",
        "         --model_name_or_path ./model_output \\\n",
        "         --train_file ./TranslateAlignRetrieve/SQuAD-es-v2.0/train-v2.0-es.json \\\n",
        "         --do_eval \\\n",
        "         --predict_file ./xquad/xquad.es.json \\\n",
        "         --overwrite_cache \\\n",
        "         --n_best_size 5 \\\n",
        "         --output_dir ./model_results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-08 21:01:49.088131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "04/08/2020 21:01:50 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "04/08/2020 21:01:50 - INFO - transformers.configuration_utils -   loading configuration file ./model_output/config.json\n",
            "04/08/2020 21:01:50 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "04/08/2020 21:01:50 - INFO - transformers.configuration_utils -   loading configuration file ./model_output/config.json\n",
            "04/08/2020 21:01:50 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "04/08/2020 21:01:50 - INFO - transformers.tokenization_utils -   Model name './model_output' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming './model_output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "04/08/2020 21:01:50 - INFO - transformers.tokenization_utils -   Didn't find file ./model_output/added_tokens.json. We won't load it.\n",
            "04/08/2020 21:01:50 - INFO - transformers.tokenization_utils -   loading file ./model_output/vocab.txt\n",
            "04/08/2020 21:01:50 - INFO - transformers.tokenization_utils -   loading file None\n",
            "04/08/2020 21:01:50 - INFO - transformers.tokenization_utils -   loading file ./model_output/special_tokens_map.json\n",
            "04/08/2020 21:01:50 - INFO - transformers.tokenization_utils -   loading file ./model_output/tokenizer_config.json\n",
            "04/08/2020 21:01:50 - INFO - transformers.modeling_utils -   loading weights file ./model_output/pytorch_model.bin\n",
            "04/08/2020 21:01:56 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, lang_id=0, learning_rate=5e-05, local_rank=-1, logging_steps=500, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='./model_output', model_type='bert', n_best_size=5, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='./model_results', overwrite_cache=True, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, predict_file='./xquad/xquad.es.json', save_steps=500, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file='./TranslateAlignRetrieve/SQuAD-es-v2.0/train-v2.0-es.json', verbose_logging=False, version_2_with_negative=False, warmup_steps=0, weight_decay=0.0)\n",
            "04/08/2020 21:01:56 - INFO - __main__ -   Loading checkpoint ./model_output for evaluation\n",
            "04/08/2020 21:01:56 - INFO - __main__ -   Evaluate the following checkpoints: ['./model_output']\n",
            "04/08/2020 21:01:56 - INFO - transformers.configuration_utils -   loading configuration file ./model_output/config.json\n",
            "04/08/2020 21:01:56 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 31002\n",
            "}\n",
            "\n",
            "04/08/2020 21:01:56 - INFO - transformers.modeling_utils -   loading weights file ./model_output/pytorch_model.bin\n",
            "04/08/2020 21:01:59 - INFO - __main__ -   Creating features from dataset file at .\n",
            "100% 48/48 [00:00<00:00, 113.99it/s]\n",
            "convert squad examples to features: 100% 1190/1190 [00:07<00:00, 169.19it/s]\n",
            "add example index and unique id: 100% 1190/1190 [00:00<00:00, 818233.08it/s]\n",
            "04/08/2020 21:02:07 - INFO - __main__ -   Saving features into cached file ./cached_dev_model_output_384\n",
            "04/08/2020 21:02:08 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "04/08/2020 21:02:08 - INFO - __main__ -     Num examples = 1271\n",
            "04/08/2020 21:02:08 - INFO - __main__ -     Batch size = 8\n",
            "Evaluating: 100% 159/159 [00:16<00:00,  9.36it/s]\n",
            "04/08/2020 21:02:25 - INFO - __main__ -     Evaluation done in total 16.986735 secs (0.013365 sec per example)\n",
            "04/08/2020 21:02:25 - INFO - transformers.data.metrics.squad_metrics -   Writing predictions to: ./model_results/predictions_.json\n",
            "04/08/2020 21:02:25 - INFO - transformers.data.metrics.squad_metrics -   Writing nbest to: ./model_results/nbest_predictions_.json\n",
            "04/08/2020 21:02:27 - INFO - __main__ -   Results: {'exact': 54.03361344537815, 'f1': 76.33693195078328, 'total': 1190, 'HasAns_exact': 54.03361344537815, 'HasAns_f1': 76.33693195078328, 'HasAns_total': 1190, 'best_exact': 54.03361344537815, 'best_exact_thresh': 0.0, 'best_f1': 76.33693195078328, 'best_f1_thresh': 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}